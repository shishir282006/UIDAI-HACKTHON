{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b3baac-51d8-44b9-9aed-2e734d8a15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Combined file 'aadhar_demographic_combined.csv' created successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = r\"C:\\Users\\Tushar\\anaconda_projects\\Pandas\\UIDAI HACKTHON\\Hackthon\\api_data_aadhar_demographic\"\n",
    "\n",
    "all_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "df_list = [pd.read_csv(file) for file in all_files]\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(\"aadhar_demographic_combined.csv\", index=False)\n",
    "\n",
    "print(\" Combined file 'aadhar_demographic_combined.csv' created successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5d7bddf-91e1-4bfd-93c2-33ac6d6f635d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file 'cleaned_demographic.csv' \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "df = pd.read_csv(\"aadhar_demographic_combined.csv\")\n",
    "\n",
    "# Step 2: Normalize state/UT names\n",
    "state_mapping = {\n",
    "    \"Orissa\": \"Odisha\",\n",
    "    \"ODISHA\": \"Odisha\",\n",
    "    \"odisha\": \"Odisha\",\n",
    "    \"Tamilnadu\": \"Tamil Nadu\",\n",
    "    \"Tamilnadu \": \"Tamil Nadu\",\n",
    "    \"Tamil Nadu\": \"Tamil Nadu\",\n",
    "    \"Jammu & Kashmir\": \"Jammu and Kashmir\",\n",
    "    \"Jammu And Kashmir\": \"Jammu and Kashmir\",\n",
    "    \"Jammu and Kashmir\": \"Jammu and Kashmir\",\n",
    "    \"Uttaranchal\": \"Uttarakhand\",\n",
    "    \"West  Bengal\": \"West Bengal\",\n",
    "    \"West Bangal\": \"West Bengal\",\n",
    "    \"West bengal\": \"West Bengal\",\n",
    "    \"WEST BENGAL\": \"West Bengal\",\n",
    "    \"WESTBENGAL\": \"West Bengal\",\n",
    "    \"west Bengal\": \"West Bengal\",\n",
    "    \"Westbengal\": \"West Bengal\",\n",
    "    \"Daman & Diu\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"Daman and Diu\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"Dadra & Nagar Haveli\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"Dadra and Nagar Haveli\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"dadar nager hawali and daman diu\": \"Dadra and Nagar Haveli and Daman and Diu\",\n",
    "    \"Pondicherry\": \"Puducherry\",\n",
    "    \"Puducherry\": \"Puducherry\",\n",
    "    \"Andaman & Nicobar Islands\": \"Andaman and Nicobar Islands\",\n",
    "    \"Andaman and Nicobar Islands\": \"Andaman and Nicobar Islands\",\n",
    "    \"Delhi\": \"Delhi\",\n",
    "    \"Chhatisgarh\": \"Chhattisgarh\",\n",
    "    \"andhra pradesh\": \"Andhra Pradesh\",\n",
    "    \"Andhra Pradesh\": \"Andhra Pradesh\"\n",
    "}\n",
    "\n",
    "df[\"state\"] = df[\"state\"].replace(state_mapping)\n",
    "\n",
    "# Step 3: Drop unwanted columns\n",
    "df = df.drop(columns=[\"date\", \"district\", \"pincode\"], errors=\"ignore\")\n",
    "\n",
    "# Step 4: Aggregate by unique state/UT and sum age columns\n",
    "clean_summary = df.groupby(\"state\")[[\"demo_age_5_17\", \"demo_age_17_\"]].sum().reset_index()\n",
    "\n",
    "# Step 5: Export cleaned dataset\n",
    "clean_summary.to_csv(\"cleaned_demographic.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned file 'cleaned_demographic.csv' \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b71448f9-b7e0-42fc-a345-e12ad711f959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned file 'final_demographic_data.csv' \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Read the dataset\n",
    "df = pd.read_csv(\"cleaned_demographic.csv\")\n",
    "\n",
    "# Step 2: Official states and UT list\n",
    "official_states_uts = [\n",
    "    \"Andaman and Nicobar Islands\",\"Andhra Pradesh\",\"Arunachal Pradesh\",\"Assam\",\"Bihar\",\n",
    "    \"Chhattisgarh\",\"Goa\",\"Gujarat\",\"Haryana\",\"Himachal Pradesh\",\"Jharkhand\",\"Karnataka\",\n",
    "    \"Kerala\",\"Madhya Pradesh\",\"Maharashtra\",\"Manipur\",\"Meghalaya\",\"Mizoram\",\"Nagaland\",\n",
    "    \"Odisha\",\"Punjab\",\"Rajasthan\",\"Sikkim\",\"Tamil Nadu\",\"Telangana\",\"Tripura\",\n",
    "    \"Uttar Pradesh\",\"Uttarakhand\",\"West Bengal\",\n",
    "    \"Chandigarh\",\"Dadra and Nagar Haveli and Daman and Diu\",\"Delhi\",\"Ladakh\",\n",
    "    \"Lakshadweep\",\"Puducherry\",\"Jammu and Kashmir\"\n",
    "]\n",
    "\n",
    "# Step 3: Filter only official states/UTs\n",
    "df_cleaned = df[df[\"state\"].isin(official_states_uts)]\n",
    "\n",
    "# Step 4: Aggregate by state/UT\n",
    "summary = df_cleaned.groupby(\"state\")[[\"demo_age_5_17\",\"demo_age_17_\"]].sum().reset_index()\n",
    "\n",
    "# Step 5: Export cleaned dataset\n",
    "summary.to_csv(\"final_demographic_data.csv\", index=False)\n",
    "\n",
    "print(\"Cleaned file 'final_demographic_data.csv' \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ef729e-ee77-4f5e-b5fd-d711b1e77148",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
